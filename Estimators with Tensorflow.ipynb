{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference link: https://medium.com/@keshan/estimators-an-easy-way-to-work-with-tensorflow-fa0a0381906f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "results = client.get(\"pqfs-mqru\", limit=10000)\n",
    "results_df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dropoff_latitude    dropoff_longitude extra fare_amount  \\\n",
      "0     40.698043823242188  -73.924278259277344   0.5           8   \n",
      "1     40.761379241943359  -73.923919677734375   0.5        15.5   \n",
      "2     40.646072387695313  -74.013160705566406   0.5        16.5   \n",
      "3     40.689033508300781  -74.000648498535156   0.5        13.5   \n",
      "4     40.663013458251953  -73.940719604492188   0.5          12   \n",
      "5     40.742111206054688  -73.867744445800781   0.5           7   \n",
      "6     40.745689392089844  -73.886192321777344   0.5           5   \n",
      "7     40.794120788574219  -73.949150085449219   0.5           7   \n",
      "8     40.679725646972656  -73.971572875976562   0.5          12   \n",
      "9     40.739658355712891  -73.917549133300781   0.5           9   \n",
      "10    40.763126373291016  -73.921028137207031   0.5           6   \n",
      "11    40.718177795410156  -73.962753295898438   0.5         3.5   \n",
      "12    40.842765808105469  -73.924903869628906   0.5        14.5   \n",
      "13    40.775833129882812   -73.90240478515625   0.5           6   \n",
      "14    40.850196838378906  -73.932029724121094   0.5          11   \n",
      "15    40.640159606933594  -73.966880798339844   0.5         4.5   \n",
      "16    40.811866760253906  -73.951583862304688   0.5          10   \n",
      "17    40.693325042724609  -73.947746276855469   0.5        15.5   \n",
      "18    40.751564025878906  -73.855522155761719   0.5         7.5   \n",
      "19    40.659637451171875  -73.976943969726563   0.5        11.5   \n",
      "20    40.709941864013672  -73.962814331054687   0.5         7.5   \n",
      "21    40.684741973876953  -73.924613952636719   0.5          15   \n",
      "22    40.820686340332031  -73.936195373535156   0.5        16.5   \n",
      "23    40.752185821533203   -74.00469970703125   0.5        22.5   \n",
      "24     40.66192626953125  -73.982398986816406   0.5           9   \n",
      "25    40.698410034179688  -73.944015502929687   0.5        13.5   \n",
      "26    40.803050994873047  -73.967994689941406   0.5          10   \n",
      "27    40.683887481689453  -73.997421264648437   0.5         6.5   \n",
      "28    40.690715789794922  -73.957466125488281   0.5           5   \n",
      "29    40.690483093261719  -73.960029602050781   0.5        19.5   \n",
      "...                  ...                  ...   ...         ...   \n",
      "9970  40.657016754150391  -73.928985595703125   0.5          13   \n",
      "9971  40.863872528076172  -73.927268981933594     0          20   \n",
      "9972  40.717811584472656  -73.959152221679688   0.5        17.5   \n",
      "9973  40.788341522216797  -73.940994262695313   0.5          21   \n",
      "9974  40.671703338623047   -73.95135498046875   0.5           5   \n",
      "9975  40.726615905761719  -73.809623718261719   0.5        10.5   \n",
      "9976  40.762432098388672  -73.827560424804687   0.5          10   \n",
      "9977  40.691253662109375  -73.997596740722656   0.5           5   \n",
      "9978  40.765983581542969  -73.823814392089844   0.5        16.5   \n",
      "9979  40.796981811523438  -73.945816040039062   0.5         8.5   \n",
      "9980  40.753818511962891  -73.869491577148438   0.5         7.5   \n",
      "9981  40.801864624023438  -73.961593627929688   0.5           7   \n",
      "9982  40.834644317626953  -73.938865661621094   0.5           7   \n",
      "9983  40.812816619873047  -73.955856323242188   0.5           8   \n",
      "9984  40.721893310546875  -73.986442565917969   0.5        45.5   \n",
      "9985  40.757038116455078  -73.886604309082031   0.5        13.5   \n",
      "9986   40.66741943359375  -73.955741882324219   0.5          13   \n",
      "9987  40.819313049316406  -73.943191528320313   0.5          16   \n",
      "9988  40.745861053466797  -73.900108337402344   0.5           7   \n",
      "9989  40.790302276611328  -73.945541381835938   0.5           4   \n",
      "9990  40.725963592529297  -73.956031799316406   0.5        23.5   \n",
      "9991  40.625591278076172   -74.02386474609375   0.5           8   \n",
      "9992  40.744163513183594  -73.880180358886719   0.5           8   \n",
      "9993  40.734745025634766  -73.952201843261719   0.5        14.5   \n",
      "9994  40.804962158203125  -73.962738037109375   0.5           5   \n",
      "9995  40.764804840087891  -73.922027587890625   0.5          24   \n",
      "9996  40.792331695556641  -73.972038269042969   0.5         6.5   \n",
      "9997    40.8424072265625  -73.938827514648438   0.5           9   \n",
      "9998  40.743942260742187  -73.898956298828125   0.5        12.5   \n",
      "9999  40.813644409179688  -73.951576232910156   0.5         6.5   \n",
      "\n",
      "     improvement_surcharge    lpep_dropoff_datetime     lpep_pickup_datetime  \\\n",
      "0                      0.3  2016-01-01T00:39:36.000  2016-01-01T00:29:24.000   \n",
      "1                      0.3  2016-01-01T00:39:18.000  2016-01-01T00:19:39.000   \n",
      "2                      0.3  2016-01-01T00:39:48.000  2016-01-01T00:19:33.000   \n",
      "3                      0.3  2016-01-01T00:38:32.000  2016-01-01T00:22:12.000   \n",
      "4                      0.3  2016-01-01T00:39:22.000  2016-01-01T00:24:01.000   \n",
      "5                      0.3  2016-01-01T00:39:35.000  2016-01-01T00:32:59.000   \n",
      "6                      0.3  2016-01-01T00:39:21.000  2016-01-01T00:34:42.000   \n",
      "7                      0.3  2016-01-01T00:39:36.000  2016-01-01T00:31:23.000   \n",
      "8                      0.3  2016-01-01T00:39:52.000  2016-01-01T00:24:40.000   \n",
      "9                      0.3  2016-01-01T00:39:23.000  2016-01-01T00:28:59.000   \n",
      "10                     0.3  2016-01-01T00:39:48.000  2016-01-01T00:32:25.000   \n",
      "11                     0.3  2016-01-01T00:39:31.000  2016-01-01T00:37:51.000   \n",
      "12                     0.3  2016-01-01T00:39:37.000  2016-01-01T00:21:39.000   \n",
      "13                     0.3  2016-01-01T00:39:49.000  2016-01-01T00:34:04.000   \n",
      "14                     0.3  2016-01-01T00:39:46.000  2016-01-01T00:26:08.000   \n",
      "15                     0.3  2016-01-01T00:39:33.000  2016-01-01T00:35:40.000   \n",
      "16                     0.3  2016-01-01T00:38:43.000  2016-01-01T00:25:05.000   \n",
      "17                     0.3  2016-01-01T00:39:49.000  2016-01-01T00:17:40.000   \n",
      "18                     0.3  2016-01-01T00:39:23.000  2016-01-01T00:31:16.000   \n",
      "19                     0.3  2016-01-01T00:39:17.000  2016-01-01T00:25:58.000   \n",
      "20                     0.3  2016-01-01T00:39:42.000  2016-01-01T00:30:54.000   \n",
      "21                     0.3  2016-01-01T00:39:36.000  2016-01-01T00:21:36.000   \n",
      "22                     0.3  2016-01-01T00:39:30.000  2016-01-01T00:18:54.000   \n",
      "23                     0.3  2016-01-01T00:39:32.000  2016-01-01T00:10:37.000   \n",
      "24                     0.3  2016-01-01T00:40:04.000  2016-01-01T00:30:53.000   \n",
      "25                     0.3  2016-01-01T00:39:52.000  2016-01-01T00:24:14.000   \n",
      "26                     0.3  2016-01-01T00:39:51.000  2016-01-01T00:30:03.000   \n",
      "27                     0.3  2016-01-01T00:39:53.000  2016-01-01T00:32:58.000   \n",
      "28                     0.3  2016-01-01T00:39:08.000  2016-01-01T00:34:53.000   \n",
      "29                     0.3  2016-01-01T00:39:32.000  2016-01-01T00:19:41.000   \n",
      "...                    ...                      ...                      ...   \n",
      "9970                   0.3  2016-01-01T01:52:30.000  2016-01-01T01:37:40.000   \n",
      "9971                     0  2016-01-01T01:53:01.000  2016-01-01T01:52:55.000   \n",
      "9972                   0.3  2016-01-01T01:52:48.000  2016-01-01T01:40:36.000   \n",
      "9973                   0.3  2016-01-01T01:52:54.000  2016-01-01T01:31:48.000   \n",
      "9974                   0.3  2016-01-01T01:52:57.000  2016-01-01T01:48:22.000   \n",
      "9975                   0.3  2016-01-01T01:52:57.000  2016-01-01T01:43:16.000   \n",
      "9976                   0.3  2016-01-01T01:52:48.000  2016-01-01T01:43:02.000   \n",
      "9977                   0.3  2016-01-01T01:52:57.000  2016-01-01T01:49:31.000   \n",
      "9978                   0.3  2016-01-01T01:49:19.000  2016-01-01T01:29:36.000   \n",
      "9979                   0.3  2016-01-01T01:52:35.000  2016-01-01T01:43:13.000   \n",
      "9980                   0.3  2016-01-01T01:52:03.000  2016-01-01T01:43:36.000   \n",
      "9981                   0.3  2016-01-01T01:52:51.000  2016-01-01T01:46:59.000   \n",
      "9982                   0.3  2016-01-01T01:52:48.000  2016-01-01T01:45:27.000   \n",
      "9983                   0.3  2016-01-01T01:52:19.000  2016-01-01T01:44:36.000   \n",
      "9984                   0.3  2016-01-01T01:52:57.000  2016-01-01T01:08:21.000   \n",
      "9985                   0.3  2016-01-01T01:52:23.000  2016-01-01T01:34:31.000   \n",
      "9986                   0.3  2016-01-01T01:52:16.000  2016-01-01T01:37:12.000   \n",
      "9987                   0.3  2016-01-01T01:52:26.000  2016-01-01T01:35:38.000   \n",
      "9988                   0.3  2016-01-01T01:53:14.000  2016-01-01T01:46:16.000   \n",
      "9989                   0.3  2016-01-01T01:52:25.000  2016-01-01T01:50:09.000   \n",
      "9990                   0.3  2016-01-01T01:52:51.000  2016-01-01T01:32:34.000   \n",
      "9991                   0.3  2016-01-01T01:52:50.000  2016-01-01T01:45:17.000   \n",
      "9992                   0.3  2016-01-01T01:52:27.000  2016-01-01T01:42:43.000   \n",
      "9993                   0.3  2016-01-01T01:53:03.000  2016-01-01T01:36:57.000   \n",
      "9994                   0.3  2016-01-01T01:53:19.000  2016-01-01T01:48:54.000   \n",
      "9995                   0.3  2016-01-01T01:53:14.000  2016-01-01T01:31:33.000   \n",
      "9996                   0.3  2016-01-01T01:53:19.000  2016-01-01T01:47:41.000   \n",
      "9997                   0.3  2016-01-01T01:53:00.000  2016-01-01T01:42:31.000   \n",
      "9998                   0.3  2016-01-01T01:53:18.000  2016-01-01T01:36:48.000   \n",
      "9999                   0.3  2016-01-01T01:53:30.000  2016-01-01T01:46:44.000   \n",
      "\n",
      "     mta_tax passenger_count payment_type     pickup_latitude  \\\n",
      "0        0.5               1            1  40.680610656738281   \n",
      "1        0.5               1            2  40.723175048828125   \n",
      "2        0.5               1            1  40.676105499267578   \n",
      "3        0.5               1            2  40.669578552246094   \n",
      "4        0.5               1            2  40.682853698730469   \n",
      "5        0.5               1            2  40.746456146240234   \n",
      "6        0.5               1            2  40.746196746826172   \n",
      "7        0.5               1            2  40.803558349609375   \n",
      "8        0.5               1            1  40.702816009521484   \n",
      "9        0.5               1            1  40.756641387939453   \n",
      "10       0.5               1            1  40.761829376220703   \n",
      "11       0.5               1            1  40.715328216552734   \n",
      "12       0.5               1            2  40.800785064697266   \n",
      "13       0.5               1            2  40.763439178466797   \n",
      "14       0.5               1            1  40.824314117431641   \n",
      "15       0.5               1            1  40.632152557373047   \n",
      "16       0.5               1            2  40.814445495605469   \n",
      "17       0.5               1            1  40.690513610839844   \n",
      "18       0.5               1            2      40.74755859375   \n",
      "19       0.5               1            2  40.684413909912109   \n",
      "20       0.5               1            2  40.693458557128906   \n",
      "21       0.5               1            1  40.713481903076172   \n",
      "22       0.5               1            2  40.788276672363281   \n",
      "23       0.5               2            1  40.752582550048828   \n",
      "24       0.5               2            1  40.678001403808594   \n",
      "25       0.5               1            1  40.672691345214844   \n",
      "26       0.5               1            1  40.821098327636719   \n",
      "27       0.5               1            2  40.677593231201172   \n",
      "28       0.5               6            2       40.6923828125   \n",
      "29       0.5               5            2  40.754131317138672   \n",
      "...      ...             ...          ...                 ...   \n",
      "9970     0.5               1            2  40.677459716796875   \n",
      "9971       0               1            1  40.863876342773438   \n",
      "9972     0.5               1            1  40.675018310546875   \n",
      "9973     0.5               1            1  40.760936737060547   \n",
      "9974     0.5               1            2  40.673252105712891   \n",
      "9975     0.5               1            2  40.721164703369141   \n",
      "9976     0.5               1            2  40.784446716308594   \n",
      "9977     0.5               1            2       40.6845703125   \n",
      "9978     0.5               1            2   40.75518798828125   \n",
      "9979     0.5               1            2  40.813556671142578   \n",
      "9980     0.5               1            2  40.742439270019531   \n",
      "9981     0.5               1            2  40.820045471191406   \n",
      "9982     0.5               1            2  40.819931030273438   \n",
      "9983     0.5               1            2  40.796012878417969   \n",
      "9984     0.5               1            1  40.649402618408203   \n",
      "9985     0.5               1            2  40.741203308105469   \n",
      "9986     0.5               2            1    40.6876220703125   \n",
      "9987     0.5               1            2  40.869773864746094   \n",
      "9988     0.5               1            2  40.743698120117187   \n",
      "9989     0.5               1            2  40.794967651367188   \n",
      "9990     0.5               1            2  40.676353454589844   \n",
      "9991     0.5               1            2  40.641448974609375   \n",
      "9992     0.5               2            2  40.754611968994141   \n",
      "9993     0.5               1            1  40.765247344970703   \n",
      "9994     0.5               1            1  40.799495697021484   \n",
      "9995     0.5               1            1  40.710689544677734   \n",
      "9996     0.5               1            1  40.785751342773437   \n",
      "9997     0.5               2            2  40.830101013183594   \n",
      "9998     0.5               1            2  40.756076812744141   \n",
      "9999     0.5               1            2  40.817115783691406   \n",
      "\n",
      "         pickup_longitude ratecodeid store_and_fwd_flag tip_amount  \\\n",
      "0     -73.928642272949219          1                  N       1.86   \n",
      "1     -73.952674865722656          1                  N          0   \n",
      "2     -73.971611022949219          1                  N       4.45   \n",
      "3        -73.989501953125          1                  N          0   \n",
      "4     -73.964729309082031          1                  N          0   \n",
      "5     -73.891143798828125          1                  N          0   \n",
      "6     -73.896675109863281          1                  N          0   \n",
      "7     -73.953353881835937          1                  N          0   \n",
      "8     -73.994064331054688          1                  N          2   \n",
      "9     -73.914131164550781          1                  N        1.6   \n",
      "10    -73.911178588867188          1                  N       1.82   \n",
      "11    -73.958168029785156          1                  N       0.96   \n",
      "12    -73.946678161621094          1                  N          0   \n",
      "13    -73.914291381835938          1                  N          0   \n",
      "14    -73.943374633789063          1                  N          2   \n",
      "15     -73.96697998046875          1                  N       1.16   \n",
      "16    -73.937843322753906          1                  N          0   \n",
      "17    -73.990364074707031          1                  N          3   \n",
      "18    -73.883827209472656          1                  N          0   \n",
      "19    -73.980354309082031          1                  N          0   \n",
      "20    -73.948799133300781          1                  N          0   \n",
      "21    -73.961967468261719          1                  N       4.08   \n",
      "22    -73.941108703613281          1                  N          0   \n",
      "23    -73.933006286621094          1                  N          3   \n",
      "24    -73.980384826660156          1                  N       3.09   \n",
      "25    -73.970344543457031          1                  N          0   \n",
      "26    -73.946258544921875          1                  N       2.26   \n",
      "27    -73.983039855957031          1                  N          0   \n",
      "28    -73.943099975585938          1                  N          0   \n",
      "29    -73.942230224609375          1                  N          0   \n",
      "...                   ...        ...                ...        ...   \n",
      "9970   -73.95916748046875          1                  N          0   \n",
      "9971  -73.927284240722656          5                  N          0   \n",
      "9972  -73.999397277832031          1                  N       5.64   \n",
      "9973  -73.950729370117188          1                  N          2   \n",
      "9974  -73.957015991210937          1                  N          0   \n",
      "9975  -73.843536376953125          1                  N          0   \n",
      "9976  -73.848587036132813          1                  N          0   \n",
      "9977  -73.991928100585938          1                  N          0   \n",
      "9978  -73.888107299804688          1                  N          0   \n",
      "9979  -73.959144592285156          1                  N          0   \n",
      "9980    -73.8731689453125          1                  N          0   \n",
      "9981  -73.955299377441406          1                  N          0   \n",
      "9982  -73.942489624023437          1                  N          0   \n",
      "9983  -73.943580627441406          1                  N          0   \n",
      "9984  -74.020164489746094          1                  N         11   \n",
      "9985  -73.853927612304688          1                  N          0   \n",
      "9986  -73.993392944335938          1                  N       2.86   \n",
      "9987  -73.916061401367187          1                  N          0   \n",
      "9988  -73.884552001953125          1                  N          0   \n",
      "9989  -73.944320678710938          1                  N          0   \n",
      "9990  -73.980201721191406          1                  N          0   \n",
      "9991  -74.017616271972656          1                  N          0   \n",
      "9992  -73.893569946289062          1                  N          0   \n",
      "9993  -73.913948059082031          1                  N       3.16   \n",
      "9994  -73.955513000488281          1                  N          1   \n",
      "9995  -73.951034545898438          1                  N        4.7   \n",
      "9996  -73.950553894042969          1                  N       1.56   \n",
      "9997  -73.936553955078125          1                  N          0   \n",
      "9998  -73.921302795410156          1                  N          0   \n",
      "9999  -73.942527770996094          1                  N          0   \n",
      "\n",
      "     tolls_amount total_amount trip_distance trip_type vendorid  \n",
      "0               0        11.16          1.46         1        2  \n",
      "1               0         16.8          3.56         1        2  \n",
      "2               0        22.25          3.79         1        2  \n",
      "3               0         14.8          3.01         1        2  \n",
      "4               0         13.3          2.55         1        2  \n",
      "5               0          8.3          1.37         1        2  \n",
      "6               0          6.3          0.57         1        2  \n",
      "7               0          8.3          1.01         1        2  \n",
      "8               0         15.3          2.46         1        2  \n",
      "9               0         11.9          1.61         1        2  \n",
      "10              0         9.12          0.72         1        2  \n",
      "11              0         5.76          0.32         1        2  \n",
      "12              0         15.8          3.54         1        2  \n",
      "13              0          7.3          1.10         1        2  \n",
      "14              0         14.3          2.28         1        2  \n",
      "15              0         6.96          0.68         1        2  \n",
      "16              0         11.3          1.36         1        2  \n",
      "17              0         19.8          3.07         1        2  \n",
      "18              0          8.8          1.52         1        2  \n",
      "19              0         12.8          2.55         1        2  \n",
      "20              0          8.8          1.57         1        2  \n",
      "21              0        20.38          3.88         1        2  \n",
      "22              0         17.8          3.97         1        2  \n",
      "23              0         26.8          5.32         1        2  \n",
      "24              0        13.39          1.76         1        2  \n",
      "25              0         14.8          3.31         1        2  \n",
      "26              0        13.56          2.21         1        2  \n",
      "27              0          7.8          1.20         1        2  \n",
      "28              0          6.3          0.61         1        2  \n",
      "29              0         20.8          5.34         1        2  \n",
      "...           ...          ...           ...       ...      ...  \n",
      "9970            0         14.3          3.20         1        2  \n",
      "9971            0           20          0.00         2        2  \n",
      "9972            0        24.44          5.74         1        2  \n",
      "9973            0         24.3          5.86         1        2  \n",
      "9974            0          6.3          0.56         1        2  \n",
      "9975            0         11.8          2.70         1        2  \n",
      "9976            0         11.3          2.29         1        2  \n",
      "9977            0          6.3          0.79         1        2  \n",
      "9978            0         17.8          3.76         1        2  \n",
      "9979            0          9.8          1.82         1        2  \n",
      "9980            0          8.8          1.43         1        2  \n",
      "9981            0          8.3          1.51         1        2  \n",
      "9982            0          8.3          1.34         1        2  \n",
      "9983            0          9.3          1.88         1        2  \n",
      "9984            0         57.8         13.68         1        2  \n",
      "9985            0         14.8          2.75         1        2  \n",
      "9986            0        17.16          2.91         1        2  \n",
      "9987            0         17.3          4.18         1        2  \n",
      "9988            0          8.3          1.37         1        2  \n",
      "9989            0          5.3          0.64         1        2  \n",
      "9990            0         24.8          6.99         1        2  \n",
      "9991            0          9.3          1.77         1        2  \n",
      "9992            0          9.3          1.62         1        2  \n",
      "9993            0        18.96          3.78         1        2  \n",
      "9994            0          7.3          0.78         1        2  \n",
      "9995            0           30          7.23         1        2  \n",
      "9996            0         9.36          1.44         1        2  \n",
      "9997            0         10.3          1.88         1        2  \n",
      "9998            0         13.8          2.37         1        2  \n",
      "9999            0          7.8          1.15         1        2  \n",
      "\n",
      "[10000 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "CSV_COLUMNS = ['dropoff_latitude', 'dropoff_longitude','pickup_latitude','pickup_longitude','passenger_count', 'fare_amount']\n",
    "FEATURES = CSV_COLUMNS[0:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[-1]\n",
    "\n",
    "# Split into train and eval as 80% and 20% respectively.\n",
    "np.random.seed(seed=1) # makes split reproducible\n",
    "msk = np.random.rand(len(results_df)) < 0.8\n",
    "\n",
    "df_train = results_df[msk]\n",
    "df_valid = results_df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need inputs function to read the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df[FEATURES].astype(float),\n",
    "    y = df[LABEL].astype(float),\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df[FEATURES].astype(float),\n",
    "    y = None,\n",
    "    batch_size = 128,\n",
    "    num_epochs = 1,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s use a very simple DNNRegressor which is a pre made Estimator with the inputs and feature columns which we created in the above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11dc1cc88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 214028.86, step = 1\n",
      "INFO:tensorflow:global_step/sec: 232.867\n",
      "INFO:tensorflow:loss = 51770.906, step = 101 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.679\n",
      "INFO:tensorflow:loss = 7103.823, step = 201 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.738\n",
      "INFO:tensorflow:loss = 6810.102, step = 301 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.323\n",
      "INFO:tensorflow:loss = 8802.282, step = 401 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.116\n",
      "INFO:tensorflow:loss = 5009.8643, step = 501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.605\n",
      "INFO:tensorflow:loss = 56944.64, step = 601 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.95\n",
      "INFO:tensorflow:loss = 11940.123, step = 701 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.46\n",
      "INFO:tensorflow:loss = 9196.859, step = 801 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.316\n",
      "INFO:tensorflow:loss = 6941.2104, step = 901 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.148\n",
      "INFO:tensorflow:loss = 3897.298, step = 1001 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.608\n",
      "INFO:tensorflow:loss = 14022.895, step = 1101 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.795\n",
      "INFO:tensorflow:loss = 7288.423, step = 1201 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.822\n",
      "INFO:tensorflow:loss = 8464.934, step = 1301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.329\n",
      "INFO:tensorflow:loss = 6561.0576, step = 1401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.146\n",
      "INFO:tensorflow:loss = 5803.635, step = 1501 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.045\n",
      "INFO:tensorflow:loss = 25919.592, step = 1601 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.539\n",
      "INFO:tensorflow:loss = 9837.635, step = 1701 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.321\n",
      "INFO:tensorflow:loss = 5545.6484, step = 1801 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.717\n",
      "INFO:tensorflow:loss = 5586.054, step = 1901 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.407\n",
      "INFO:tensorflow:loss = 10896.166, step = 2001 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.019\n",
      "INFO:tensorflow:loss = 10456.835, step = 2101 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.66\n",
      "INFO:tensorflow:loss = 6530.8394, step = 2201 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.592\n",
      "INFO:tensorflow:loss = 6208.0664, step = 2301 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.165\n",
      "INFO:tensorflow:loss = 7252.45, step = 2401 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.645\n",
      "INFO:tensorflow:loss = 8968.15, step = 2501 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.2\n",
      "INFO:tensorflow:loss = 10853.559, step = 2601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.984\n",
      "INFO:tensorflow:loss = 3492.4722, step = 2701 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.247\n",
      "INFO:tensorflow:loss = 4409.2603, step = 2801 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.292\n",
      "INFO:tensorflow:loss = 8577.25, step = 2901 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.838\n",
      "INFO:tensorflow:loss = 8727.156, step = 3001 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.259\n",
      "INFO:tensorflow:loss = 7813.202, step = 3101 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.852\n",
      "INFO:tensorflow:loss = 6028.46, step = 3201 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.82\n",
      "INFO:tensorflow:loss = 31441.145, step = 3301 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.573\n",
      "INFO:tensorflow:loss = 6631.146, step = 3401 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.493\n",
      "INFO:tensorflow:loss = 11287.818, step = 3501 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.826\n",
      "INFO:tensorflow:loss = 8033.49, step = 3601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.931\n",
      "INFO:tensorflow:loss = 3524.3416, step = 3701 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.162\n",
      "INFO:tensorflow:loss = 15571.695, step = 3801 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.748\n",
      "INFO:tensorflow:loss = 8475.391, step = 3901 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.251\n",
      "INFO:tensorflow:loss = 7372.3223, step = 4001 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.417\n",
      "INFO:tensorflow:loss = 8225.111, step = 4101 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.495\n",
      "INFO:tensorflow:loss = 6948.9043, step = 4201 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.22\n",
      "INFO:tensorflow:loss = 8544.84, step = 4301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.935\n",
      "INFO:tensorflow:loss = 9872.189, step = 4401 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.375\n",
      "INFO:tensorflow:loss = 8157.3696, step = 4501 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.389\n",
      "INFO:tensorflow:loss = 7182.9497, step = 4601 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.5\n",
      "INFO:tensorflow:loss = 7759.6895, step = 4701 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.796\n",
      "INFO:tensorflow:loss = 10920.408, step = 4801 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.866\n",
      "INFO:tensorflow:loss = 7779.045, step = 4901 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.147\n",
      "INFO:tensorflow:loss = 7801.511, step = 5001 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.366\n",
      "INFO:tensorflow:loss = 6051.248, step = 5101 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.315\n",
      "INFO:tensorflow:loss = 10048.726, step = 5201 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.719\n",
      "INFO:tensorflow:loss = 7327.0312, step = 5301 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.688\n",
      "INFO:tensorflow:loss = 3903.499, step = 5401 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.116\n",
      "INFO:tensorflow:loss = 5302.147, step = 5501 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.717\n",
      "INFO:tensorflow:loss = 13199.962, step = 5601 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.808\n",
      "INFO:tensorflow:loss = 10595.509, step = 5701 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.665\n",
      "INFO:tensorflow:loss = 7909.079, step = 5801 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.871\n",
      "INFO:tensorflow:loss = 3087.6228, step = 5901 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.94\n",
      "INFO:tensorflow:loss = 11507.182, step = 6001 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.725\n",
      "INFO:tensorflow:loss = 8129.6855, step = 6101 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.792\n",
      "INFO:tensorflow:loss = 8085.507, step = 6201 (0.322 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6283 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 81.173325.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x10c195fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "OUTDIR = 'taxi_trained'\n",
    "\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-01-02:06:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6283\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-01-02:06:54\n",
      "INFO:tensorflow:Saving dict for global step 6283: average_loss = 84.86123, global_step = 6283, loss = 10390.196\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6283: taxi_trained/model.ckpt-6283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation dataset = 9.212015151977539\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, name, df):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(df, 1))\n",
    "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
